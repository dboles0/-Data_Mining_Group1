{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Import\n",
    "\n",
    "* if you want to work localy with with half the data using individual pandas df <br\\>*(my computer does not have sufficient local memory to join all tables)*\n",
    "\n",
    "attempted stratagy (merge pd_df until memory bound then print to csv file then try again on csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import pandas as pd\n",
    "\n",
    "def JSON_to_dataFrame(file): \n",
    "    fp = open(file, encoding=\"utf8\")\n",
    "    df = pd.DataFrame([json.loads(x) for x in fp.readlines()])\n",
    "    fp.close\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# review_df = JSON_to_dataFrame(\"../Group_Project/Group1/review.json\")\n",
    "# business_df = JSON_to_dataFrame(\"../Group_Project/Group1/business.json\")\n",
    "# user_df = JSON_to_dataFrame(\"../Group_Project/Group1/user.json\")\n",
    "# tip_df = JSON_to_dataFrame(\"../Group_Project/Group1/tip.json\")\n",
    "# checkin_df = JSON_to_dataFrame(\"../Group_Project/Group1/checkin.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "## Merging Files\n",
    "* paired the information down by combining the review business and user json files in to one merged csv file for processing (rbu_merged.csv) (deleted the other files and will be using this one to save space on my computer, if we need additional columns we will have to run this over adding the column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns {cool, funny} cause I dont think we will use them\n",
    "# review contains: {business_id, date, review_id, stars, text, useful, user_id}\n",
    "# review_df = review_df.drop(['cool','funny'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename columns to identify the table\n",
    "# review contains: {review_business_id, review_date, review_review_id, review_stars, review_text, review_useful, review_user_id}\n",
    "# review_df = review_df.rename(columns={'business_id': 'review_business_id', 'date': 'review_date', 'review_id': 'review_review_id', 'stars': 'review_stars', 'text': 'review_text', 'useful': 'review_useful', 'user_id': 'review_user_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop columns {postal_code, categories, address, attributes, categories, hours} \n",
    "# remaining fields: {business_id, city, is_open, latitude, longitude, name, review_count, stars, state}\n",
    "# business_df = business_df.drop(['postal_code','categories', 'address', 'attributes', 'categories', 'hours'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename to reflect business table: {review_business_id, review_date, review_review_id, review_stars, review_text, review_useful, review_user_id}\n",
    "# business contains: {business_business_id, business_city, business_is_open, business_latitude, business_longitude, business_name, business_review_count, business_stars, business_state}\n",
    "# business_df = business_df.rename(columns={'business_id': 'business_business_id', 'city': 'business_city', 'is_open': 'business_is_open', 'latitude': 'business_latitude', 'longitude':'business_longitude','name':'business_name','review_count':'business_review_count','stars':'business_stars', 'state':'business_state'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rb_merge = pd.merge(review_df, business_df, left_on='review_business_id', right_on='business_business_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remaining fields: {business_id, city, is_open, latitude, longitude, name, review_count, stars, state}\n",
    "# user_df = user_df.drop(['compliment_cool','compliment_cute','compliment_funny','compliment_hot','compliment_list','compliment_more','compliment_note','compliment_photos', 'compliment_plain', 'compliment_profile', 'compliment_writer', 'cool', 'elite', 'funny'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remaining fields: {user_average_stars', 'user_fans', 'user_friends', user_name', 'user_review_count', 'user_useful', 'user_user_id','user_yelping_since'}\n",
    "# user_df = user_df.rename(columns={'average_stars': 'user_average_stars', 'fans': 'user_fans', 'friends': 'user_friends', 'name': 'user_name', 'review_count':'user_review_count','useful':'user_useful','user_id':'user_user_id','yelping_since':'user_yelping_since'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rbu_merge = pd.merge(rb_merge, user_df, left_on='review_user_id', right_on='user_user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rbu_merge.to_csv(r'../Group_Project/Group1/rbu_merge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "## Convert Merged File into DataFrame (using rbu_merge.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    df = pd.read_csv(\"../Group_Project/Group1/rbu_merge.csv\", dtype={'review_business_id':str, 'review_date':str, 'review_review_id':str, 'review_stars':float, 'review_text':str, 'review_useful':int, 'review_user_id':str, 'business_business_id':str, 'business_city':str, 'business_is_open':int, 'business_latitude':float, 'business_longitude':float, 'business_name':str, 'business_review_count':int, 'business_stars':float, 'business_state':str, 'user_average_stars':float, 'user_fans':int, 'user_friends':str, 'user_name':str, 'user_review_count':int, 'user_useful':int, 'user_user_id':str,'user_yelping_since':str})\n",
    "except: \n",
    "    del()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                0\n",
       "review_business_id        0\n",
       "review_date               0\n",
       "review_review_id          0\n",
       "review_stars              0\n",
       "review_text               1\n",
       "review_useful             2\n",
       "review_user_id            2\n",
       "business_business_id      2\n",
       "business_city             5\n",
       "business_is_open          2\n",
       "business_latitude         2\n",
       "business_longitude        2\n",
       "business_name             2\n",
       "business_review_count     2\n",
       "business_stars            2\n",
       "business_state            2\n",
       "user_average_stars        2\n",
       "user_fans                 2\n",
       "user_friends              2\n",
       "user_name                12\n",
       "user_review_count         4\n",
       "user_useful               4\n",
       "user_user_id              4\n",
       "user_yelping_since        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## GCP Import\n",
    "* login cradentaials provided to work with yelp_db database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyMySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySql Server is nessisary to connect to GCP\n",
    "* https://dev.mysql.com/downloads/mysql/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymysql, os, sys, json\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read json file\n",
    "file = \"Group1/review.json\"\n",
    "\n",
    "json_data = open(file, encoding=\"utf8\")\n",
    "json_obj = [json.loads(x) for x in json_data.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = len(json_obj)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validate data before inserting\n",
    "# TODO: check if string is the right type \n",
    "# TODO: check for duplicate data\n",
    "# TODO: check for bad formats (date)\n",
    "\n",
    "def validate_string(val): \n",
    "    if val != None: \n",
    "            if type(val) is int: \n",
    "                return str(val).encode('utf-8')\n",
    "            else: \n",
    "                return val\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing takes to long so I used multiprocessing to speed up importing to host\n",
    "* executing insert into gcp is atomic\n",
    "\n",
    "this will take over 4 days to import one table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_review(cursor, item, lock): \n",
    "          \n",
    "    review_id = validate_string(item['review_id'])\n",
    "    business_id = validate_string(item['business_id'])\n",
    "    cool = validate_string(item['cool'])\n",
    "    date = validate_string(item['date'])\n",
    "    funny = validate_string(item['funny'])\n",
    "    stars = validate_string(item['stars'])\n",
    "    text = validate_string(item['text'])\n",
    "    useful = validate_string(item['useful'])\n",
    "    user_id = validate_string(item['user_id'])\n",
    "    \n",
    "    query = \"INSERT INTO review(review_id,business_id,cool,date,funny,stars,text,useful,user_id) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    args = (review_id, business_id, cool, date, funny, stars, text, useful, user_id)\n",
    "    lock.acquire()\n",
    "    cursor.execute(query, args)\n",
    "    lock.release()\n",
    "    \n",
    "    clear_output()\n",
    "    cnt.value = cnt.value + 1\n",
    "    print(cnt.value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to GCP MySql db insert data into review table\n",
    "con = pymysql.connect(host = '104.198.65.208', user='root', password = 'hackme', db = 'yelp_db')\n",
    "\n",
    "cnt = mp.Value('i', 0)\n",
    "lock = mp.Lock()\n",
    "pool = mp.Pool()\n",
    "\n",
    "\n",
    "try: \n",
    "    with con.cursor() as cursor:\n",
    "        \n",
    "        # parse json data to SQL\n",
    "        # use map to update each row in GCP\n",
    "        result = pool.map([ insert_review(cursor, item, lock) for item in json_obj ])\n",
    "            \n",
    "finally:\n",
    "    con.commit()\n",
    "    con.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
