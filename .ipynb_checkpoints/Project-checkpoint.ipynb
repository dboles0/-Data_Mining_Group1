{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Import\n",
    "\n",
    "* if you want to work localy with with half the data using individual pandas df <br\\>*(my computer does not have sufficient local memory to join all tables)*\n",
    "\n",
    "attempted stratagy (merge pd_df until memory bound then print to csv file then try again on csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, csv\n",
    "import pandas as pd\n",
    "\n",
    "def JSON_to_dataFrame(file): \n",
    "    fp = open(file, encoding=\"utf8\")\n",
    "    df = pd.DataFrame([json.loads(x) for x in fp.readlines()])\n",
    "    fp.close\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_df = JSON_to_dataFrame(\"../Group_Project/Group1/review.json\")\n",
    "tip_df = JSON_to_dataFrame(\"../Group_Project/Group1/tip.json\")\n",
    "checkin_df = JSON_to_dataFrame(\"../Group_Project/Group1/checkin.json\")\n",
    "business_df = JSON_to_dataFrame(\"../Group_Project/Group1/business.json\")\n",
    "user_df = JSON_to_dataFrame(\"../Group_Project/Group1/user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_merge = pd.merge(review_df, tip_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rtb_merge = pd.merge(rt_merge, business_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rtbc_merge = pd.merge(rtb_merge, checkin_df, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rtbc_merge.to_csv(r'Group1/rtbc_merge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCP Import\n",
    "* login cradentaials provided to work with yelp_db database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyMySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySql Server is nessisary to connect to GCP\n",
    "* https://dev.mysql.com/downloads/mysql/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymysql, os, sys, json\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read json file\n",
    "file = \"Group1/review.json\"\n",
    "\n",
    "json_data = open(file, encoding=\"utf8\")\n",
    "json_obj = [json.loads(x) for x in json_data.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = len(json_obj)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validate data before inserting\n",
    "# TODO: check if string is the right type \n",
    "# TODO: check for duplicate data\n",
    "# TODO: check for bad formats (date)\n",
    "\n",
    "def validate_string(val): \n",
    "    if val != None: \n",
    "            if type(val) is int: \n",
    "                return str(val).encode('utf-8')\n",
    "            else: \n",
    "                return val\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing to long so I used multiprocessing to speed up importing to host\n",
    "* executing insert into gcp is atomic\n",
    "\n",
    "this will take over 4 days to import one table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_review(cursor, item, lock): \n",
    "          \n",
    "    review_id = validate_string(item['review_id'])\n",
    "    business_id = validate_string(item['business_id'])\n",
    "    cool = validate_string(item['cool'])\n",
    "    date = validate_string(item['date'])\n",
    "    funny = validate_string(item['funny'])\n",
    "    stars = validate_string(item['stars'])\n",
    "    text = validate_string(item['text'])\n",
    "    useful = validate_string(item['useful'])\n",
    "    user_id = validate_string(item['user_id'])\n",
    "    \n",
    "    query = \"INSERT INTO review(review_id,business_id,cool,date,funny,stars,text,useful,user_id) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    args = (review_id, business_id, cool, date, funny, stars, text, useful, user_id)\n",
    "    lock.acquire()\n",
    "    cursor.execute(query, args)\n",
    "    lock.release()\n",
    "    \n",
    "    clear_output()\n",
    "    cnt.value = cnt.value + 1\n",
    "    print(cnt.value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to GCP MySql db insert data into review table\n",
    "con = pymysql.connect(host = '104.198.65.208', user='root', password = 'hackme', db = 'yelp_db')\n",
    "\n",
    "cnt = mp.Value('i', 0)\n",
    "lock = mp.Lock()\n",
    "pool = mp.Pool()\n",
    "\n",
    "\n",
    "try: \n",
    "    with con.cursor() as cursor:\n",
    "        \n",
    "        # parse json data to SQL\n",
    "        # use map to update each row in GCP\n",
    "        result = pool.map([ insert_review(cursor, item, lock) for item in json_obj ])\n",
    "            \n",
    "finally:\n",
    "    con.commit()\n",
    "    con.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
