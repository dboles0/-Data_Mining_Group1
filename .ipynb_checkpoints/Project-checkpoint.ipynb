{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Import\n",
    "\n",
    "* working localy trim the data to ensure you can work with it locally <br/>\n",
    "*(local computer doesn't have sufficient memory to join all tables so trim down appropriate attributes)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# If import's not installed pip install all\n",
    "\n",
    "# import sys\n",
    "# try: \n",
    "#    !{sys.executable} -m pip install plotly --upgrade\n",
    "#    !{sys.executable} -m pip install geopandas==0.3.0\n",
    "#    !{sys.executable} -m pip install pyshp==1.2.10\n",
    "#    !{sys.executable} -m pip install shapely==1.6.3\n",
    "#    !{sys.executable} -m pip install \"notebook>=5.3\" \"ipywidgets>=7.2\"\n",
    "#    !{sys.executable} -m pip install chart_studio\n",
    "#    !{sys.executable} -m pip install plotly-geo\n",
    "#    !{sys.executable} -m pip install folium\n",
    "# except ImportError: \n",
    "#    print(\"already installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running plotly = 4.2.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imports | path info | json to pandas dataframe util funciton \n",
    "import json, csv, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "\n",
    "# clustering / unsupervised learning import\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# plotly imports \n",
    "import plotly\n",
    "from plotly import __version__\n",
    "print('running plotly = {}'.format(__version__))\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# path info\n",
    "root_path = \"/Users/2015mbp16gb256gb/Documents/school/Fall_2019/4502-Data_Mining/Group_Project/Group1/yelp_dataset/\"\n",
    "rbu_path = root_path + \"rbu_merge.json\"\n",
    "filtered_merge_path = root_path + \"filtered_merge.json\"\n",
    "\n",
    "# converstion util function\n",
    "def JSON_to_dataFrame(file): \n",
    "    \n",
    "    fp = open(file, encoding=\"utf8\")\n",
    "    json_obj = [ json.loads(x) for x in fp.readlines() ] \n",
    "    df = pd.DataFrame(json_obj)\n",
    "    fp.close\n",
    "    return df\n",
    "\n",
    "# for plotly ofline \n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing The Buiness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# add text to plot \n",
    "%%time\n",
    "\n",
    "business_df = JSON_to_dataFrame(root_path + \"business.json\")\n",
    "business_df['text'] = business_df['state'] + ', ' + business_df['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# display states/province in business file\n",
    "business_df.groupby('state').state.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 11 main states found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kmeans can be sensative to outliers but most of the information is naturally clumped so we dont have to worry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# find all kmeans and groups\n",
    "def find_df_groups_plus_kmeans(df, lat, lon, n_clusters): \n",
    "    # transform the data \n",
    "    coordinates_df = df[[lat, lon]].copy()\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    coordinates = pca.fit_transform(coordinates_df)\n",
    "    \n",
    "    #Train model\n",
    "    kmeans = KMeans(n_clusters=n_clusters).fit(coordinates)\n",
    "    \n",
    "    # assign lables\n",
    "    df['labels'] = pd.DataFrame(kmeans.labels_)\n",
    "    \n",
    "    return (df, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "# plot elbo method\n",
    "Sum_of_squared_distances = []\n",
    "K = 15\n",
    "\n",
    "for k in range(1, K):\n",
    "    business_df, km = find_df_groups_plus_kmeans(business_df, 'latitude', 'longitude', k)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# group using k=10\n",
    "n_clusters = 10\n",
    "business_df, km = find_df_groups_plus_kmeans(business_df, 'latitude', 'longitude', n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets see what states connect to to clusters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# group the cluster and evaluate lables\n",
    "groupby_lables = business_df.groupby('labels').agg(lambda x:x.value_counts().index[0])\n",
    "state_lables = list(groupby_lables['state'])\n",
    "cnt = 0\n",
    "for i in state_lables: \n",
    "    print(cnt, i)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's plot cluster information for nationwide visualization\"\"\"\n",
    "\"\"\"\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Scattergeo(\n",
    "        lon = business_df['longitude'],\n",
    "        lat = business_df['latitude'],\n",
    "        text = business_df['text'],\n",
    "        mode = 'markers',\n",
    "        marker_color = business_df['labels'],\n",
    "        ))\n",
    "\n",
    "fig.update_layout(\n",
    "        title = 'US Cluster<br>(hover for spicific informaiton)',\n",
    "        geo_scope='usa',\n",
    "    )\n",
    "fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper look at clustered business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# look at the difference between the review count and stars\n",
    "national_review_mean = business_df[\"review_count\"].mean()\n",
    "national_stars_mean = business_df[\"stars\"].mean()\n",
    "print(\"national_stars_mean = \", national_stars_mean)\n",
    "print(\"national_review_mean = \", national_review_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# means of the clustered info\n",
    "def sortSecond(val): \n",
    "    return val[1] \n",
    "\n",
    "review_count = []\n",
    "rating_stars = []\n",
    "ratio_open_close = []\n",
    "count = []\n",
    "for n in range(n_clusters):\n",
    "    indexes = business_df[business_df[\"labels\"] != n].index\n",
    "    temp = business_df.copy()\n",
    "    temp.drop(indexes, inplace=True)\n",
    "    rating_stars.append((n, temp[\"stars\"].mean()))\n",
    "    review_count.append((n, temp[\"review_count\"].mean()))\n",
    "    count.append((n, temp.count()))\n",
    "    ratio_open_close.append((n, 1 - temp[\"is_open\"].sum() / temp[\"is_open\"].count() ))\n",
    "\n",
    "print(\"Star's mean per cluster = \")\n",
    "rating_stars.sort(key = sortSecond, reverse = True)\n",
    "for i, value in rating_stars: \n",
    "    print(state_lables[i], value)\n",
    "    \n",
    "review_count.sort(key = sortSecond, reverse = True)\n",
    "print(\"\\nReview_count's mean per cluster = \")\n",
    "for i, value in review_count: \n",
    "    print(state_lables[i], value) \n",
    "    \n",
    "ratio_open_close.sort(key = sortSecond, reverse = True)    \n",
    "print(\"\\nRatio of closed businesses per cluster = \")\n",
    "for i, value in ratio_open_close: \n",
    "    print(state_lables[i], \"=\", value) \n",
    "    \n",
    "print(\"\\nCount per cluster = \")\n",
    "for i, value in count: \n",
    "    print(\"--\"+state_lables[i]+\"--\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "### Merging Files and filter out anything not in the NV cluster\n",
    "* merge review, business, and user. Clean format to ensure no merge conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "review_df = JSON_to_dataFrame(root_path + \"review.json\")\n",
    "business_df = JSON_to_dataFrame(root_path + \"business.json\")\n",
    "user_df = JSON_to_dataFrame(root_path + \"user.json\")\n",
    "# tip_df = JSON_to_dataFrame(root_path + \"tip.json\")                     /not used\n",
    "# checkin_df = JSON_to_dataFrame(root_path + \"checkin.json\")             /not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# utility function to make a dict of columns with table name added\n",
    "# used for the renaming of column names\n",
    "def make_columns(lst, base):\n",
    "    ret = {}\n",
    "    for i in lst:\n",
    "        ret[i] = base + '_' + i\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# return dataframe with column names updated to \"table + _column_name\"\n",
    "def process_df(a_df, table): \n",
    "\n",
    "    col_list = [i for i in a_df]\n",
    "    new_dict = make_columns(col_list, table)\n",
    "    return a_df.rename(columns=new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# review col = ['business_id', 'cool', 'date', 'funny', 'review_id', 'stars', 'text', 'useful', 'user_id']\n",
    "\n",
    "# ***Update review_df*** \n",
    "review_drop = ['cool','funny']\n",
    "review_df = review_df.drop(review_drop, axis=1)\n",
    "\n",
    "review_df = process_df(review_df, 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# business col = \n",
    "# ['address','attributes','business_id','categories','city','hours','is_open',              \n",
    "# 'latitude','longitude','name','postal_code','review_count','stars','state']                              \n",
    "\n",
    "# ***Update business_df***\n",
    "business_drop = ['address', 'postal_code']\n",
    "business_df = business_df.drop(business_drop, axis=1)\n",
    "\n",
    "business_df = process_df(business_df, 'business')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rb_merge = pd.merge(review_df, business_df, left_on='review_business_id', right_on='business_business_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# user col = \n",
    "# ['average_stars','compliment_cool','compliment_cute','compliment_funny','compliment_hot','compliment_list',           \n",
    "# 'compliment_more','compliment_note','compliment_photos','compliment_plain','compliment_profile','compliment_writer', \n",
    "# 'cool','elite','fans','friends','funny','name','review_count','useful','user_id','yelping_since']   \n",
    "\n",
    "# ***Update _user_df***\n",
    "user_drop = ['average_stars','compliment_cool','compliment_cute','compliment_funny','compliment_hot','compliment_list','compliment_more','compliment_note','compliment_photos','compliment_plain','compliment_profile','compliment_writer','cool', 'elite', 'fans','friends','funny']\n",
    "user_df = user_df.drop(user_drop, axis=1)\n",
    "\n",
    "user_df = process_df(user_df, 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rbu_merge = pd.merge(rb_merge, user_df, left_on='review_user_id', right_on='user_user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rbu_drop = ['review_business_id','review_user_id']\n",
    "rbu_merge = rbu_merge.drop(rbu_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# drop any elements not in the cluster to clean\n",
    "rbu_merge, km = find_df_groups_plus_kmeans(rbu_merge, 'business_latitude', 'business_longitude', n_clusters)\n",
    "filtered_merge = rbu_merge[rbu_merge['labels'] == 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "### Write Merged DataFrame Back To Json file for quicker processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# convert df to json format util funciton\n",
    "def df_to_json(df, path):\n",
    "    new_dict = {}\n",
    "    num_col = len([i for i in df])\n",
    "\n",
    "    with open(r'{}'.format(path), 'w') as writer: \n",
    "\n",
    "        for row in df.itertuples():\n",
    "            \n",
    "            for idx, col in enumerate(df): \n",
    "                if type(row[idx+1]) == int: \n",
    "                    new_dict[col] = int(row[idx+1])\n",
    "                if type(row[idx+1]) == float: \n",
    "                    new_dict[col] = float(row[idx+1])\n",
    "                else: \n",
    "                    new_dict[col] = str(row[idx+1])\n",
    "                \n",
    "            writer.write(json.dumps(new_dict) + '\\n')\n",
    "            new_dict = {}         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "df_to_json(filtered_merge, filtered_merge_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## (Start) Open \"filtered_merge\" file for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 2min 14s, total: 3min 46s\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "merged_df = JSON_to_dataFrame(filtered_merge_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It looks like the business star ratings are more of a normal distribution than the review stars. we will use this attribute compair to 5 star ratings for businesses.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it looks like the business star ratings are more of a normal distribution than the review stars\n",
      "this could be due to bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a20947650>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call regplot on each axes\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "\n",
    "sns.distplot(merged_df.review_stars, kde=False, ax=ax1)\n",
    "sns.distplot(merged_df.business_stars, kde=False, ax=ax2)\n",
    "\n",
    "#sns.set(rc={'figure.figsize':(10,5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# thoughts on what can be done with the data\n",
    "\n",
    "\n",
    "# Nieve Base \n",
    "# first use business 5 star to classify as either 1 or 0\n",
    "# then find the calssifications as P(\"x-class\" | \"5 star = yes\") * P(\"5 star = yes\")\n",
    "# do this for all classificatoins to get the probability a business in this classification will get a 5 star rating\n",
    "\n",
    "# the rule R can be assessed by coverage and accuracy\n",
    "# coverage = the percentage of tuples that are covered by the rule\n",
    "# accurecy = the percentage of tupples that the rule can correctly classify\n",
    "\n",
    "# look into the information gain for each attribute given a classification and 5 star\n",
    "# to do this we will have to transpose each attributs into a nominal or binary value\n",
    "# (within each category) total \"5 star = yes\" = P and total \"5 star = no\" = N\n",
    "# I(P,N) = - (P/total in dataset) * log_2(P/total in dataset) - (N/total in data set) * log_2(N/total in dataset)\n",
    "# # Info_Dataset(D) = I(total number of yes, total number of no)\n",
    "# to get the information gain form the category attribute we need P and N from each category to\n",
    "# Info_category(D) = (# of each in category) / (total in dataset) * I(P,N) + Sum(X) for X as each category\n",
    "# Info_Dataset(D) - Info_category(D) \n",
    "# do this for all attribues to find what to split on \n",
    "\n",
    "# coverage (R) = (how many entries meet the \"x-class\" | \"5 star = yes\" criteria) / (total number of entries)\n",
    "# accurecy (R) = (num of \"5 star = yes\") / (how many entries meet the \"x-class\" | \"5 star = yes\" criteria)\n",
    "\n",
    "# usefull vs avg stars\n",
    "# cool vs average stars\n",
    "# funny vs average stars\n",
    "# number of friends vs avg stars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Find the probability of a category attaining a 5 star rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add attributes \n",
    "1 or 0 depending on five_star avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if business has rating of 5 star add 1 to list othrwise 0\n",
    "# add this information as a new column\n",
    "def update_list(val): \n",
    "    if val == 5: \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "merged_df['five_star_business'] = [update_list(x) for x in merged_df['business_stars'] ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 or 0 depending on local chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# if business has multiple entries calassify as chain with a 1 otherwise 0\n",
    "unique_list = []\n",
    "\n",
    "def check_unique(lst, entry): \n",
    "    for i in lst: \n",
    "        if i == entry: \n",
    "            return 1\n",
    "        \n",
    "    lst.append(entry)\n",
    "    return 0\n",
    "\n",
    "merged_df['is_chain'] = [check_unique(unique_list, x) for x in merged_df.business_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (X) geting a 5 star rating; where X is a given category\n",
    "(first lets look at the probability of getting a five star vs not getting a five star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# find the probability of yes and no\n",
    "N = merged_df['five_star_business'].count()\n",
    "\n",
    "num_yes = merged_df[merged_df['five_star_business']==1].five_star_business.count()\n",
    "num_no = N - num_yes\n",
    "\n",
    "print(\"C_1 = yes (five star rating)\")\n",
    "print(\"C_2 = no  (five star rating)\")\n",
    "print(\"P(C_i|X) = P(X| C_i) P(C_i)\")\n",
    "print(\"P(C_i)\")\n",
    "\n",
    "stars_yes = num_yes / N\n",
    "stars_no = num_no / N\n",
    "print(\"P(five_star = \\\"yes\\\") = {}/{} = {}\".format(num_yes, N, stars_yes)) \n",
    "print(\"P(five_star = \\\"no\\\") = {}/{} = {}\".format(num_no, N, stars_no))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(now determin probabilities based on a given calss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function for calculating pobabilities\n",
    "def prob_entry(df, yes_total, no_total): \n",
    "    five_star_yes = df[df['five_star_business']==1].five_star_business.count()\n",
    "    five_star_no = df[df['five_star_business']==0].five_star_business.count()\n",
    "    prob = (five_star_yes / yes_total, five_star_no / no_total)\n",
    "    return prob\n",
    "\n",
    "def calc_probabilities(column_for_prob, num_yes, num_no): \n",
    "    prob_five_star = []\n",
    "    # group and find the probabilities based on group\n",
    "    for name, group in merged_df.groupby(column_for_prob): \n",
    "        prob_five_star.append((name, prob_entry(group, num_yes, num_no)))\n",
    "        \n",
    "    # split array into lists based on attibute\n",
    "    list_of_column_for_prob = []\n",
    "    list_of_prob_yes = []\n",
    "    list_of_porb_no = []\n",
    "\n",
    "    for name, (yes, no) in prob_five_star: \n",
    "        list_of_column_for_prob.append(name)\n",
    "        list_of_prob_yes.append(yes)\n",
    "        list_of_porb_no.append(no)\n",
    "        \n",
    "    # combine lists and add to dataframe    \n",
    "    zippedList =  list(zip(list_of_column_for_prob, list_of_prob_yes, list_of_porb_no))\n",
    "    \n",
    "    return pd.DataFrame(zippedList, columns = [column_for_prob, 'yes_prob', 'no_prob'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### P(Category| C_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10: P(category|five_star = \\\"yes\\\") and  P(category|five_star = \\\"no\\\")\")\n",
    "prob_categories_df = calc_probabilities('business_categories', num_yes, num_no)\n",
    "prob_categories_df.sort_values(by=\"yes_prob\", ascending=False)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bar = merged_df.business_stars.mean()\n",
    "std_dev = merged_df.business_stars.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = merged_df.groupby('business_categories')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "again = pd.DataFrame(new)\n",
    "again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hist(df): \n",
    "    b_stars_list = []\n",
    "\n",
    "    for i, row in enumerate(df.itertuples()): \n",
    "        b_stars_list.append((i, row.business_stars))\n",
    "    \n",
    "    print(b_stars_list[:5])\n",
    "show_hist(merged_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(merged_df[['review_stars', 'business_stars']])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clustered NV informaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once the we have a resonable amount of business lets visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# find unique businesses\n",
    "def make_unique(df, col1): \n",
    "    unique = []\n",
    "    booliens = []\n",
    "\n",
    "    for x in df[col1]:\n",
    "        if x not in unique:\n",
    "            booliens.append(True)\n",
    "            unique.append(x)\n",
    "        else:\n",
    "            booliens.append(False)\n",
    "\n",
    "    return booliens\n",
    "\n",
    "booliens = []\n",
    "\n",
    "arg1 = 'business_business_id'\n",
    "booliens = make_unique(merged_df, arg1)\n",
    "\n",
    "unique_values = pd.Series(booliens)\n",
    "\n",
    "# use as filter for unique values\n",
    "unique_review_df = merged_df[unique_values]\n",
    "\n",
    "# look at the number of business in the area\n",
    "unique_review_df.business_business_id.count()\n",
    "\n",
    "# look at all the businesses with average star rating over 4\n",
    "unique_review_df[(unique_review_df['business_stars'] > 4) & (unique_review_df['business_is_open'] == '1')].business_stars.count() \n",
    "\n",
    "test_df = unique_review_df[(unique_review_df['business_stars'] > 4) & (unique_review_df['business_is_open'] == '1')].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# visualize location points using folium\n",
    "import folium\n",
    " \n",
    "NV = (36.188820, -115.207720)\n",
    " \n",
    "# for speed purposes\n",
    "\n",
    "\n",
    "colors = ['#000000', '#cc0099', '#3186cc']\n",
    "\n",
    "  \n",
    "# create empty map zoomed in on San Francisco\n",
    "m = folium.Map(location=NV, zoom_start=10)\n",
    "\n",
    "\n",
    "# add a marker for every record in the filtered data, use a clustered view\n",
    "for lat, lon in zip(test_df['business_latitude'], test_df['business_longitude']):    \n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=1,\n",
    "        fill=True,\n",
    "        ).add_to(m) \n",
    "\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_path = root_path + 'test.json' \n",
    "\n",
    "test_df = JSON_to_dataFrame(test_in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_out_path = root_path + 'test_out.json' \n",
    "\n",
    "parse_DataFrame1(test_df, test_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_df = JSON_to_dataFrame(test_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_DataFrame_to_Json(a_df_1, a_df_2): \n",
    "    \n",
    "    df_list_1 = []\n",
    "    df_list_2 = []\n",
    "    catch_list = []\n",
    "    \n",
    "    for row in a_df_1.itertuples():\n",
    "            \n",
    "            for idx, col in enumerate(a_df_1):\n",
    "                df_list_1.append((type(row[idx]), col))\n",
    "                \n",
    "    for row_2 in a_df_2.itertuples():\n",
    "            \n",
    "            for idx_2, col_2 in enumerate(a_df_2):\n",
    "                df_list_2.append((type(row[idx_2]), col_2))\n",
    "                \n",
    "    for x,y in zip(df_list_1, df_list_2): \n",
    "        if x != y: \n",
    "            catch_list.append((x, y))\n",
    "            \n",
    "    for i in catch_list: \n",
    "        print(i)             # dataFrams have different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSON_to_dataFrame_2(file): \n",
    "    \n",
    "    fp = open(file, encoding=\"utf8\")\n",
    "    json_obj = [ json.loads(x) for x in fp.readlines() [-500000:]] \n",
    "    df = pd.DataFrame(json_obj)\n",
    "    fp.close\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = JSON_to_dataFrame_2(rbu_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller scale test on business set\n",
    "test_DataFrame_to_Json(rbu_merge, rbu_complete_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on full merged data set\n",
    "test_DataFrame_to_Json(rbu_merge, rbu_complete_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to check file given error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_input_output(test_in_path, test_out_path, log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input_output(a_test_in_path, a_test_out_path, a_log_path):\n",
    "    line_count = 0\n",
    "    char_count = 0\n",
    "    save1 = \"\"\n",
    "    save2 = []\n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "    \n",
    "    with open(a_test_in_path, 'r') as read1, open(a_test_out_path, 'r') as read2: \n",
    "        for x, y in zip(read1, read2):\n",
    "            x = x.strip()\n",
    "            y = y.strip()\n",
    "            \n",
    "            in_line = x.split()\n",
    "            out_line = y.split()\n",
    "            for word1, word2 in zip(in_line, out_line):\n",
    "                \n",
    "                save2.append(word1)\n",
    "                \n",
    "                if cnt1 > 5:\n",
    "                    save2.pop(0)\n",
    "                cnt1 = cnt1 + 1\n",
    "\n",
    "            \n",
    "                word_list = list(word2)\n",
    "                \n",
    "                for char in word_list: \n",
    "                    save1 = save1 + char\n",
    "                    if cnt2 > 70: \n",
    "                        save1 = save1[1:]\n",
    "                    \n",
    "                    if char_count == 139: \n",
    "                        print(save1)\n",
    "                        print(\" \".join(save2))\n",
    "                        \n",
    "                    char_count = char_count + 1\n",
    "                    cnt2 += 1\n",
    "                \n",
    "            line_count = line_count + 1\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_out_path, 'r') as reader: \n",
    "    for i in reader: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## GCP Import\n",
    "* login cradentaials provided to work with yelp_db database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyMySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySql Server is nessisary to connect to GCP\n",
    "* https://dev.mysql.com/downloads/mysql/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql, os, sys, json\n",
    "from IPython.display import clear_output\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file\n",
    "file = \"Group1/review.json\"\n",
    "\n",
    "json_data = open(file, encoding=\"utf8\")\n",
    "json_obj = [json.loads(x) for x in json_data.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(json_obj)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate data before inserting\n",
    "# TODO: check if string is the right type \n",
    "# TODO: check for duplicate data\n",
    "# TODO: check for bad formats (date)\n",
    "\n",
    "def validate_string(val): \n",
    "    if val != None: \n",
    "            if type(val) is int: \n",
    "                return str(val).encode('utf-8')\n",
    "            else: \n",
    "                return val\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing takes to long so I used multiprocessing to speed up importing to host\n",
    "* executing insert into gcp is atomic\n",
    "\n",
    "this will take over 4 days to import one table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_review(cursor, item, lock): \n",
    "          \n",
    "    review_id = validate_string(item['review_id'])\n",
    "    business_id = validate_string(item['business_id'])\n",
    "    cool = validate_string(item['cool'])\n",
    "    date = validate_string(item['date'])\n",
    "    funny = validate_string(item['funny'])\n",
    "    stars = validate_string(item['stars'])\n",
    "    text = validate_string(item['text'])\n",
    "    useful = validate_string(item['useful'])\n",
    "    user_id = validate_string(item['user_id'])\n",
    "    \n",
    "    query = \"INSERT INTO review(review_id,business_id,cool,date,funny,stars,text,useful,user_id) VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "    args = (review_id, business_id, cool, date, funny, stars, text, useful, user_id)\n",
    "    lock.acquire()\n",
    "    cursor.execute(query, args)\n",
    "    lock.release()\n",
    "    \n",
    "    clear_output()\n",
    "    cnt.value = cnt.value + 1\n",
    "    print(cnt.value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to GCP MySql db insert data into review table\n",
    "con = pymysql.connect(host = '104.198.65.208', user='root', password = 'hackme', db = 'yelp_db')\n",
    "\n",
    "cnt = mp.Value('i', 0)\n",
    "lock = mp.Lock()\n",
    "pool = mp.Pool()\n",
    "\n",
    "\n",
    "try: \n",
    "    with con.cursor() as cursor:\n",
    "        \n",
    "        # parse json data to SQL\n",
    "        # use map to update each row in GCP\n",
    "        result = pool.map([ insert_review(cursor, item, lock) for item in json_obj ])\n",
    "            \n",
    "finally:\n",
    "    con.commit()\n",
    "    con.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
